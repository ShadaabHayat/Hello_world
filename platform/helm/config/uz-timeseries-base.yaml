# All keys must be flat.
connector.class: "io.confluent.connect.s3.S3SinkConnector"
errors.tolerance: "all"
key.converter: "org.apache.kafka.connect.storage.StringConverter"
key.converter.schemas.enable: true
locale: "en-US"
partition.field.format.path: true
partition.field.name: "rdc, env"
partitioner.class: "com.canelmas.kafka.connect.FieldAndTimeBasedPartitioner"
path.format: "'year'=YYYY/'month'=MM/'day'=dd"
s3.region: "us-east-1"
schema.compatibility: "FULL_TRANSITIVE"
storage.class: "io.confluent.connect.s3.storage.S3Storage"
timestamp.extractor: "RecordField"
timestamp.field: "aicore_ingestion_time"
timezone: "UTC"
transforms: "InsertRDCInfo, InsertEnvInfo,InsertTimeStamp,tsFormat"
transforms.InsertEnvInfo.static.field: "env"
transforms.InsertEnvInfo.type: "org.apache.kafka.connect.transforms.InsertField${ESCAPE_CHAR}Value"
transforms.InsertRDCInfo.static.field: "rdc"
transforms.InsertRDCInfo.type: "org.apache.kafka.connect.transforms.InsertField${ESCAPE_CHAR}Value"
transforms.InsertTimeStamp.timestamp.field: "aicore_ingestion_time"
transforms.InsertTimeStamp.type: "org.apache.kafka.connect.transforms.InsertField${ESCAPE_CHAR}Value"
transforms.tsFormat.field: "aicore_ingestion_time"
transforms.tsFormat.format: "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"
transforms.tsFormat.target.type: "string"
transforms.tsFormat.type: "org.apache.kafka.connect.transforms.TimestampConverter${ESCAPE_CHAR}Value"
value.converter: "io.confluent.connect.avro.AvroConverter"
value.converter.schema.registry.url: "http://cp-schema-registry-common-kafka.common.svc.cluster.local:8081"
value.converter.schemas.enable: false
behavior.on.null.values: "ignore"
errors.deadletterqueue.context.headers.enable: true
errors.deadletterqueue.topic.replication.factor: "1"
flush.size: "10000"
format.class: "io.confluent.connect.s3.format.parquet.ParquetFormat"
parquet.codec: "gzip"
partition.duration.ms: "3600000"
rotate.interval.ms: "-1"
rotate.schedule.interval.ms: "300000"
s3.part.size: "5242880"
tasks.max: "20"
topics: "uz_activity_logs_pii_stripped"
topics.dir: "uz-data-bronze"
aws.access.key.id: $AWS_ACCESS_KEY_ID
aws.secret.access.key: $AWS_SECRET_ACCESS_KEY
aws.credentials.provider: "com.amazonaws.auth.AWSStaticCredentialsProvider"
